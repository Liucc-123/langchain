{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LCEL（Lang Chain Expression Language）语法的使用\n",
    "未使用管道符`|`的示例（这里直接使用本地模型，因为便宜好用）"
   ],
   "id": "f1e5e7cb031019bf"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-22T13:03:39.774652Z",
     "start_time": "2025-10-22T13:03:33.506287Z"
    }
   },
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOllama(model=\"deepseek-r1:7b\", base_url=\"http://192.168.31.74:11434\")\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "#以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"笑话\": \"有一天，一只数学书去看了医生，因为它觉得自己的根号值太大了。\"\\n}\\n```' additional_kwargs={} response_metadata={'model': 'deepseek-r1:7b', 'created_at': '2025-10-22T13:03:39.7042511Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6136135200, 'load_duration': 2090299800, 'prompt_eval_count': 26, 'prompt_eval_duration': 43166200, 'eval_count': 204, 'eval_duration': 3849854200, 'model_name': 'deepseek-r1:7b', 'model_provider': 'ollama'} id='lc_run--577ee08a-fe6f-46e8-8a25-52cd45bcbb79-0' usage_metadata={'input_tokens': 26, 'output_tokens': 204, 'total_tokens': 230}\n",
      "{'笑话': '有一天，一只数学书去看了医生，因为它觉得自己的根号值太大了。'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "示例 2：使用chain，将 prompt、model 及parse 组合在一起",
   "id": "b047a8a3c9a5ec24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T13:09:58.217612Z",
     "start_time": "2025-10-22T13:09:52.390778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt_template |  chat_model | parser\n",
    "response = chain.invoke(input={\"question\": joke_query})\n",
    "print(type(response))\n",
    "print( response)"
   ],
   "id": "abdce1307b401efc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'笑话': {'value': '为什么植物 ANSI码总是很累？\\n\\n因为它们总要在编码中找寻归宿！'}}\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
