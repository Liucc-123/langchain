{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1、 模型调用的分类\n",
    "\n",
    "角度1：按照模型功能的不同\n",
    "\n",
    "非对话模型：（LLMs、Text Model）\n",
    "\n",
    "对话模型：（Chat Models）  (推荐)\n",
    "\n",
    "嵌入模型：（Embedding Models） (放到最后RAG章节讲解)\n",
    "\n",
    "\n",
    "角度2：按照模型调用时，参数书写的位置的不同（api-key、base_url、model-name）\n",
    "\n",
    "硬编码的方式：将参数书写在代码中\n",
    "\n",
    "使用环境变量的方式\n",
    "\n",
    "使用配置文件的方式 (推荐)\n",
    "\n",
    "角度3：具体API的调用\n",
    "\n",
    "使用LangChain提供的API (推荐)\n",
    "\n",
    "使用OpenAI 官方的API\n",
    "\n",
    "使用其它平台提供的API\n",
    "\n",
    "\n",
    "# 2、角度1：非对话模型的调用\n"
   ],
   "id": "12bf235f6d02f0d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:49:39.672503Z",
     "start_time": "2025-10-23T12:49:34.319302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAI\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "\n",
    "###########核心代码############\n",
    "llm = OpenAI()\n",
    "str = llm.invoke(\"写一首关于春天的诗\")  # 直接输入字符串\n",
    "print(str)\n",
    "print(type(str))"
   ],
   "id": "6bc1c5da87577157",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "春风拂过田野\n",
      "万物苏醒欢歌\n",
      "草木抽出新芽\n",
      "花儿绽放笑颜\n",
      "\n",
      "蜂儿忙碌采蜜\n",
      "鸟儿欢唱高枝\n",
      "阳光温暖如丝\n",
      "春雨滋润大地\n",
      "\n",
      "田野变成彩色画卷\n",
      "青翠的稻穗摇曳\n",
      "金黄的麦田飘香\n",
      "春天的色彩绚烂\n",
      "\n",
      "春风吹散冬日的寒冷\n",
      "带来生机和希望\n",
      "让我们跟随春天的脚步\n",
      "迎接新的一天的曙光\n",
      "\n",
      "春天，是生命的奇迹\n",
      "是希望的象征\n",
      "让我们用心感受\n",
      "这美妙的春天气息\n",
      "\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2、角度1：对话模型的调用",
   "id": "eb3640984fb46ec3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "\n",
    "########核心代码############\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"我是人工智能助手，我叫小智\"),\n",
    "    HumanMessage(content=\"你好，我是小明，很高兴认识你\")\n",
    "]\n",
    "\n",
    "#输入：list[basemessage]\n",
    "#输出：AIMessage\n",
    "response = chat_model.invoke(messages)  # 输入消息列表\n",
    "\n",
    "print(type(response))  # <class 'langchain_core.messages.ai.AIMessage'>\n",
    "print(response.content)"
   ],
   "id": "e0499aa3e9f8c831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2、角度1：嵌入模型的调用",
   "id": "d18bab70e5b578e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "\n",
    "#############\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "res1 = embeddings_model.embed_query('我是文档中的数据')\n",
    "print(res1)\n",
    "# 打印结果：[-0.004306625574827194, 0.003083756659179926, -0.013916781172156334, ...., ]"
   ],
   "id": "f5d25adfdd0966a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3、角度2：参数位置不同举例\n",
    "\n",
    "\n",
    "## 3.1 硬编码的方式\n",
    "\n",
    "以对话模型为例："
   ],
   "id": "1d038858595ed7e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# 调用非对话模型：\n",
    "# llms = OpenAI(...)\n",
    "\n",
    "\n",
    "# 调用对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    #必须要设置的3个参数\n",
    "    model_name=\"gpt-4o-mini\",   #默认使用的是gpt-3.5-turbo模型\n",
    "    base_url=\"https://api.openai-proxy.org/v1\",\n",
    "    api_key=\"sk-zD4CB2Qe7G2Dp6veCfPRSxeDx9fQPxCUIfOFAk20ETV5B2VA\",\n",
    "\n",
    ")\n",
    "\n",
    "# 调用模型\n",
    "response = chat_model.invoke(\"什么是langchain?\")\n",
    "\n",
    "# 查看响应的文本\n",
    "# print(response.content)\n",
    "print(response)"
   ],
   "id": "7ab34ce303baa0f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "演示非对话模型",
   "id": "9046baef4e2dcffc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# 调用非对话模型：\n",
    "llm = OpenAI(\n",
    "    #必须要设置的3个参数\n",
    "    #model_name=\"gpt-4o-mini\",   #默认使用的是gpt-3.5-turbo模型\n",
    "    base_url=\"https://api.openai-proxy.org/v1\",\n",
    "    api_key=\"sk-zD4CB2Qe7G2Dp6veCfPRSxeDx9fQPxCUIfOFAk20ETV5B2VA\",\n",
    "\n",
    ")\n",
    "\n",
    "# 调用模型\n",
    "response = llm.invoke(\"什么是langchain?\")\n",
    "\n",
    "# 查看响应的文本\n",
    "print(response)"
   ],
   "id": "a32d8bc517f5ec19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 使用环境变量的方式\n",
    "\n",
    "说明：使用环境变量的方式，在jupyter中执行不合适，需要在.py文件中执行"
   ],
   "id": "4dff51aeddf00408"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 1、获取对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    #必须要设置的3个参数\n",
    "    model_name=\"gpt-4o-mini\",   #默认使用的是gpt-3.5-turbo模型\n",
    "    base_url=os.environ[\"OPENAI_BASE_URL\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "\n",
    ")\n",
    "\n",
    "# 2、调用模型\n",
    "response = chat_model.invoke(\"什么是langchain?\")\n",
    "\n",
    "# 3、查看响应的文本\n",
    "# print(response.content)\n",
    "print(response)"
   ],
   "id": "89938ded24d226e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3 使用配置文件的方式（推荐）\n",
    "\n",
    "使用.env的配置文件\n",
    "\n",
    "方式1："
   ],
   "id": "a120f34a5748b612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "#加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# 1、获取对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    #必须要设置的3个参数\n",
    "    model_name=\"gpt-4o-mini\",   #默认使用的是gpt-3.5-turbo模型\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY1\"),\n",
    "\n",
    ")\n",
    "\n",
    "# 2、调用模型\n",
    "response = chat_model.invoke(\"什么是langchain?\")\n",
    "\n",
    "# 3、查看响应的文本\n",
    "# print(response.content)\n",
    "print(response)"
   ],
   "id": "532928d4e9d6617f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "方式2：",
   "id": "e9b7527b32a91cce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "#加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "\n",
    "\n",
    "# 1、获取对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    #必须要设置的3个参数\n",
    "    #model_name=\"gpt-4o-mini\",   #默认使用的是gpt-3.5-turbo模型\n",
    "    #当没有显式的声明base_url和api_key的时候，默认会从环境变量中查找\n",
    ")\n",
    "\n",
    "# 2、调用模型\n",
    "response = chat_model.invoke(\"什么是langchain?\")\n",
    "\n",
    "# 3、查看响应的文本\n",
    "# print(response.content)\n",
    "print(response)"
   ],
   "id": "97da8cecb0039bbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "体会其它参数的使用：",
   "id": "3ed35050f2909c4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "#加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "\n",
    "\n",
    "# 1、获取对话模型：\n",
    "chat_model = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    max_tokens=20,\n",
    ")\n",
    "\n",
    "# 2、调用模型\n",
    "response = chat_model.invoke(\"什么是langchain?\")\n",
    "\n",
    "# 3、查看响应的文本\n",
    "# print(response.content)\n",
    "print(response)"
   ],
   "id": "8a0a7869175e5d14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4、角度3：使用各个平台的API的调用大模型（了解）\n",
    "\n",
    "## 4.1 OpenAI的方式\n",
    "\n",
    "调用非对话模型"
   ],
   "id": "809a2690456160c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 从环境变量读取API密钥（推荐安全存储）\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-zD4CB2Qe7G2Dp6veCfPRSxeDx9fQPxCUIfOFAk20ETV5B2VA\",  #填写自己的api-key\n",
    "    base_url=\"https://api.openai-proxy.org/v1\") #通过代码示例获取\n",
    "\n",
    "# 调用Completion接口\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",  # 非对话模型\n",
    "    prompt=\"请将以下英文翻译成中文：\\n'Artificial intelligence will reshape the future.'\",\n",
    "    max_tokens=100,  # 生成文本最大长度\n",
    "    temperature=0.7,  # 控制随机性\n",
    ")\n",
    "# 提取结果\n",
    "print(response.choices[0].text.strip())"
   ],
   "id": "adb73afa3bb6ef79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "调用对话模型",
   "id": "3f39c8bfbbdf32f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-zD4CB2Qe7G2Dp6veCfPRSxeDx9fQPxCUIfOFAk20ETV5B2VA\", #填写自己的api-key\n",
    "    base_url=\"https://api.openai-proxy.org/v1\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # 对话模型\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个乐于助人的智能AI小助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请你介绍一下你自己\"}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ],
   "id": "bdc7985be09eca2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 百度千帆平台",
   "id": "a6dc028fabd75765"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"bce-v3/ALTAK-Ynzfb6RBYeGiyI08yEXuf/21f994aeb874bbc0c55c3c4dc37a6b9b0cccaac1\",  # 千帆bearer token\n",
    "    base_url=\"https://qianfan.baidubce.com/v2\",  # 千帆域名\n",
    "    default_headers={\"appid\": \"app-y3sQKuT2\"}   # 用户在千帆上的appid，非必传\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"ernie-4.0-turbo-8k\", # 预置服务请查看模型列表，定制服务请填入API地址\n",
    "    messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "              {'role': 'user', 'content': 'Hello！'}]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ],
   "id": "33deee722a4a498b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.3 使用阿里云百炼平台\n",
    "\n",
    "方式1：使用OpenAI的方式"
   ],
   "id": "aaeabc121f045c4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),  # 如何获取API Key：https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\",  # 此处以 deepseek-r1 为例，可按需更换模型名称。\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': '9.9和9.11谁大'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 通过reasoning_content字段打印思考过程\n",
    "print(\"思考过程：\")\n",
    "print(completion.choices[0].message.reasoning_content)\n",
    "\n",
    "# 通过content字段打印最终答案\n",
    "print(\"最终答案：\")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "79c91f16148b4279",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "方式2：使用dashscope",
   "id": "64c81810e902d02d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dashscope\n",
    "\n",
    "messages = [\n",
    "    {'role': 'user', 'content': '你是谁？'}\n",
    "]\n",
    "\n",
    "response = dashscope.Generation.call(\n",
    "    # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    model=\"deepseek-r1\",  # 此处以 deepseek-r1 为例，可按需更换模型名称。\n",
    "    messages=messages,\n",
    "    # result_format参数不可以设置为\"text\"。\n",
    "    result_format='message'\n",
    ")\n",
    "\n",
    "print(\"=\" * 20 + \"思考过程\" + \"=\" * 20)\n",
    "print(response.output.choices[0].message.reasoning_content)\n",
    "print(\"=\" * 20 + \"最终答案\" + \"=\" * 20)\n",
    "print(response.output.choices[0].message.content)"
   ],
   "id": "41dbcc342514ff3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.4 智谱的GLM\n",
    "\n",
    "方式1：使用OpenAI的方式"
   ],
   "id": "60de89ff1e65ba19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"4806f93a9fa948b3ad0da1ec6f989261.sRf49YGloBNigTox\",\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"glm-4.5\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个聪明且富有创造力的小说作家\"},\n",
    "        {\"role\": \"user\", \"content\": \"请你作为童话故事大王，写一篇短篇童话故事\"}\n",
    "    ],\n",
    "    top_p=0.7,\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "b620021006633d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "方式2：使用langchain的方式",
   "id": "3a0bcec871bc756d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# 创建LLM实例\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model=\"glm-4.5\",\n",
    "    openai_api_key=\"4806f93a9fa948b3ad0da1ec6f989261.sRf49YGloBNigTox\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "# 创建消息\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一个有用的AI助手\"),\n",
    "    HumanMessage(content=\"请介绍一下人工智能的发展历程\")\n",
    "]\n",
    "\n",
    "# 调用模型\n",
    "response = llm(messages)\n",
    "print(response.content)"
   ],
   "id": "bd8d72ed301c879c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.5 硅基流动平台的演示",
   "id": "ad480de02e685f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"Qwen/QwQ-32B\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What opportunities and challenges will the Chinese large model industry face in 2025?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer sk-auciaxqpzchyauiovpzkwrjhznkzepozralhwleyrdoyjani\", #填写自己的api-key\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ],
   "id": "69b934b44b6cf80f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
