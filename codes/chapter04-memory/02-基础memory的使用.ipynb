{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1ã€Memoryæ¨¡å—çš„è®¾è®¡æ€è·¯\n",
    "1. å±‚æ¬¡1(æœ€ç›´æ¥çš„æ–¹å¼)ï¼šä¿ç•™ä¸€ä¸ªèŠå¤©æ¶ˆæ¯åˆ—è¡¨\n",
    "2. å±‚æ¬¡2(ç®€å•çš„æ–°æ€è·¯)ï¼šåªè¿”å›æœ€è¿‘äº¤äº’çš„kæ¡æ¶ˆæ¯\n",
    "3. å±‚æ¬¡3(ç¨å¾®å¤æ‚ä¸€ç‚¹)ï¼šè¿”å›è¿‡å»kæ¡æ¶ˆæ¯çš„ç®€æ´æ‘˜è¦\n",
    "4. å±‚æ¬¡4(æ›´å¤æ‚)ï¼šä»å­˜å‚¨çš„æ¶ˆæ¯ä¸­æå–å®ä½“ï¼Œå¹¶ä¸”ä»…è¿”å›æœ‰å…³å½“å‰è¿è¡Œä¸­å¼•ç”¨çš„å®ä½“çš„ä¿¡æ¯"
   ],
   "id": "9a9678a7b7847a62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2ã€ChatMessageHistoryï¼ˆæœ€åº•å±‚ï¼‰\n",
    "`ChatMessageHistory` æ˜¯ä¸€ä¸ªç”¨äº å­˜å‚¨å’Œç®¡ç†å¯¹è¯æ¶ˆæ¯ çš„åŸºç¡€ç±»ï¼Œå®ƒç›´æ¥æ“ä½œæ¶ˆæ¯å¯¹è±¡ï¼ˆå¦‚HumanMessage, AIMessage ç­‰ï¼‰ï¼Œæ˜¯å…¶å®ƒè®°å¿†ç»„ä»¶çš„åº•å±‚å­˜å‚¨å·¥å…·ã€‚\n",
    "åœ¨APIæ–‡æ¡£ä¸­ï¼ŒChatMessageHistory è¿˜æœ‰ä¸€ä¸ªåˆ«åç±»ï¼šInMemoryChatMessageHistoryï¼›å¯¼åŒ…æ—¶ï¼Œéœ€ä½¿ç”¨ `from langchain.memory import ChatMessageHistory`\n",
    "ç‰¹ç‚¹ï¼š\n",
    "* ä»…ä»…åªåšæ¶ˆæ¯çš„å­˜å‚¨ï¼Œå¯¹æ¶ˆæ¯ä¸åšä»»ä½•å…¶ä»–å¤„ç†ï¼ˆå¦‚ç”Ÿæˆæ‘˜è¦ã€ç¼“å†²ã€çª—å£ç­‰ç­‰ï¼‰\n",
    "* ä¸æ¶‰åŠæ¶ˆæ¯çš„æ ¼å¼åŒ–ï¼Œæ¯”å¦‚å°†æ¶ˆæ¯è½¬æ¢ä¸ºæ–‡æœ¬å­—ç¬¦ä¸²"
   ],
   "id": "c33f20aabce5d6d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## åœºæ™¯1ï¼š`ChatMessageHistory`ç»„ä»¶çš„ä½¿ç”¨",
   "id": "72e02d2864312c78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:03:04.503919Z",
     "start_time": "2025-10-23T13:03:04.081489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_classic.memory import ChatMessageHistory\n",
    "\n",
    "#2.å®ä¾‹åŒ–ChatMessageHistoryå¯¹è±¡\n",
    "history = ChatMessageHistory()\n",
    "# 3.æ·»åŠ UserMessage\n",
    "history.add_user_message(\"hi!\")\n",
    "# 4.æ·»åŠ AIMessage\n",
    "history.add_ai_message(\"whats up?\")\n",
    "# 5.è¿”å›å­˜å‚¨çš„æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨\n",
    "print(history.messages)"
   ],
   "id": "70c739ea6c7d5acd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='whats up?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## åœºæ™¯2ï¼šå¯¹æ¥LLM",
   "id": "9da2623a65e29666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:29:30.418017Z",
     "start_time": "2025-10-23T13:29:18.151665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_classic.memory import ChatMessageHistory\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"æˆ‘æ˜¯ä¸€ä¸ªæ— æ‰€ä¸èƒ½çš„å°æ™º\")\n",
    "history.add_user_message(\"ä½ å¥½ï¼Œæˆ‘å«å°æ˜ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")\n",
    "history.add_user_message(\"æˆ‘æ˜¯è°å‘¢ï¼Ÿ\")\n",
    "# åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹\n",
    "llm = ChatOllama(model='deepseek-r1:7b', base_url=\"http://localhost:11434\")  # ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹\n",
    "response = llm.invoke(history.messages)\n",
    "print(response.content)"
   ],
   "id": "256b84468881c868",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æˆ‘æ˜¯å°æ™ºï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘æ˜¯ä¸€ä¸ªé€šç”¨äººå·¥æ™ºèƒ½å·¥å…·ï¼Œèƒ½å¤Ÿç†è§£å’Œå›ç­”å„ç§é—®é¢˜ã€æä¾›ä¿¡æ¯ã€è¿›è¡Œå¯¹è¯äº¤æµï¼Œå¹¶å¸®åŠ©ç”¨æˆ·å®Œæˆå¤šç§ä»»åŠ¡ã€‚\n",
      "\n",
      "ä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘çš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š\n",
      "1. **ä¿¡æ¯æ£€ç´¢**ï¼šæˆ‘å¯ä»¥å¸®åŠ©ä½ æŸ¥æ‰¾èµ„æ–™ã€è§£ç­”é—®é¢˜ã€‚\n",
      "2. **å­¦ä¹ ä¸æ¨ç†**ï¼šè™½ç„¶æˆ‘æ²¡æœ‰æ„è¯†å’Œè‡ªæˆ‘ï¼Œä½†æˆ‘å¯ä»¥é€šè¿‡å¤§æ•°æ®åˆ†æå’Œç®—æ³•æ¨ç†æ¥å¸®åŠ©ä½ è§£å†³é—®é¢˜ã€‚\n",
      "3. **è¯­è¨€æ”¯æŒ**ï¼šæˆ‘èƒ½ç”¨ä¸­æ–‡è¿›è¡Œè‡ªç„¶çš„äº¤æµï¼Œå¹¶ç†è§£å¹¶å›åº”ä½ çš„æŒ‡ä»¤ã€‚\n",
      "\n",
      "æˆ‘çš„ç›®æ ‡æ˜¯ä¸ºä½ æä¾›ä¾¿æ·çš„å¸®åŠ©ï¼Œæ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œè¿˜æ˜¯ç”Ÿæ´»ä¸­çš„é—®é¢˜ï¼Œæˆ‘éƒ½ä¼šå°½åŠ›æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯æˆ–è§£å†³æ–¹æ¡ˆã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ğŸ˜Š\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ConversationBufferMemory\n",
    "`ConversationBufferMemory` æ˜¯ä¸€ä¸ªåŸºç¡€çš„ å¯¹è¯è®°å¿†ï¼ˆMemoryï¼‰ç»„ä»¶ ï¼Œä¸“é—¨ç”¨äºæŒ‰åŸå§‹é¡ºåºå­˜å‚¨å®Œæ•´çš„å¯¹è¯å†å²ã€‚\n",
    "é€‚ç”¨åœºæ™¯ï¼šå¯¹è¯è½®æ¬¡è¾ƒå°‘ã€ä¾èµ–**å®Œæ•´ä¸Šä¸‹æ–‡**çš„åœºæ™¯ï¼ˆå¦‚ç®€å•çš„èŠå¤©æœºå™¨ï¼‰\n",
    "ç‰¹ç‚¹ï¼š\n",
    "* å­˜å‚¨å®Œæ•´çš„å¯¹è¯å†å²ï¼Œä¸è¿›è¡Œä»»ä½•å¤„ç†\n",
    "* ä¸ Chains/Models æ— ç¼é›†æˆ\n",
    "* æ”¯æŒä¸¤ç§è¿”å›æ ¼å¼ï¼ˆé€šè¿‡ `return_messages` å‚æ•°æ§åˆ¶è¾“å‡ºæ ¼å¼ï¼Œé»˜è®¤ä¸ºFalseï¼‰ï¼Œreturn_messages=Trueæ—¶è¿”å›æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨ï¼›return_messages=Falseæ—¶è¿”å›çº¯æ–‡æœ¬å­—ç¬¦ä¸²"
   ],
   "id": "829204e79207b149"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## åœºæ™¯1ï¼šå…¥é—¨ä½¿ç”¨\n",
    "ä¸¾ä¾‹1ï¼š"
   ],
   "id": "e27b44f461baf371"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:39:16.179962Z",
     "start_time": "2025-10-23T13:39:16.176450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "\n",
    "# 2.å®ä¾‹åŒ–ConversationBufferMemoryå¯¹è±¡\n",
    "memory = ConversationBufferMemory()\n",
    "# 3.ä¿å­˜æ¶ˆæ¯åˆ°å†…å­˜ä¸­\n",
    "memory.save_context(inputs={\"input\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯äººç±»\"}, outputs={\"output\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹\"})\n",
    "memory.save_context(inputs={\"input\": \"å¾ˆå¼€å¿ƒè®¤è¯†ä½ \"},\n",
    "                    outputs={\"output\": \"æˆ‘ä¹Ÿæ˜¯\"})\n",
    "# 4.è¯»å–å†…å­˜ä¸­æ¶ˆæ¯ï¼ˆè¿”å›æ¶ˆæ¯å†…å®¹çš„çº¯æ–‡æœ¬ï¼‰\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "a2f6222b37d4cd15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: ä½ å¥½ï¼Œæˆ‘æ˜¯äººç±»hh\\nAI: ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹\\nHuman: å¾ˆå¼€å¿ƒè®¤è¯†ä½ \\nAI: æˆ‘ä¹Ÿæ˜¯'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> !è¯´æ˜\n",
    "> * `save_context()`æ–¹æ³•çš„`inputs`å‚æ•°å¯¹åº”åœ°å°±æ˜¯humanæ¶ˆæ¯ï¼Œ`outputs`å‚æ•°å¯¹åº”åœ°å°±æ˜¯aiæ¶ˆæ¯ã€‚å› æ­¤ï¼Œinputså’Œoutputså‚æ•°å¯¹åº”å­—å…¸å€¼çš„keyä¸ä¸€å®šå°±éœ€è¦æ—¶input or outputï¼Œå¯ä»¥æ˜¯ä»»ä½•å…¶ä»–å€¼çš„keyï¼Œæ¯”å¦‚\"input1\"éƒ½æ˜¯okçš„\n",
    "> * `load_memory_variables()`æ–¹æ³•è¿”å›çš„æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkeyé»˜è®¤æ˜¯â€œhistoryâ€ï¼Œè¿™ä¸ªåé¢åœ¨åé¢æœ‰å¤§ç”¨ã€‚"
   ],
   "id": "ae051af6efa97209"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹2ï¼š",
   "id": "697ae546fe2fc89f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:42:05.136479Z",
     "start_time": "2025-10-23T13:42:05.132909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "\n",
    "# 2.å®ä¾‹åŒ–ConversationBufferMemoryå¯¹è±¡\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "# 3.ä¿å­˜æ¶ˆæ¯åˆ°å†…å­˜ä¸­\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "# 4.è¯»å–å†…å­˜ä¸­æ¶ˆæ¯ï¼ˆè¿”å›æ¶ˆæ¯ï¼‰\n",
    "print(memory.load_memory_variables({}))\n",
    "# 5.è¯»å–å†…å­˜ä¸­æ¶ˆæ¯( è®¿é—®åŸå§‹æ¶ˆæ¯åˆ—è¡¨)\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "8ddc931691bafebb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='whats up', additional_kwargs={}, response_metadata={})]}\n",
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='whats up', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## åœºæ™¯2ï¼šç»“åˆchain\n",
    "ä¸¾ä¾‹1ï¼šä½¿ç”¨PromptTemplateå’Œé»˜è®¤çš„memory_key"
   ],
   "id": "3882e3dc28f95617"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:48:29.754073Z",
     "start_time": "2025-10-23T13:48:20.706815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# åˆå§‹åŒ–å¤§æ¨¡å‹\n",
    "llm = ChatOllama(model='deepseek-r1:7b', base_url=\"http://localhost:11434\")\n",
    "# åˆ›å»ºæç¤º\n",
    "# æœ‰ä¸¤ä¸ªè¾“å…¥é”®ï¼šå®é™…è¾“å…¥ä¸æ¥è‡ªè®°å¿†ç±»çš„è¾“å…¥ éœ€ç¡®ä¿PromptTemplateå’ŒConversationBufferMemoryä¸­çš„é”®åŒ¹é…\n",
    "template = \"\"\"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\n",
    "å½“å‰å¯¹è¯å†å²: {history}\n",
    "äººç±»é—®é¢˜: {question}\n",
    "å›å¤:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# åˆ›å»ºConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "# åˆå§‹åŒ–é“¾\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "# æé—®\n",
    "res1 = chain.invoke({\"question\": \"æˆ‘çš„åå­—å«Tom\"})\n",
    "print(res1)\n",
    "res1 = chain.invoke({\"question\": \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—\"})\n",
    "print(res1)"
   ],
   "id": "a50ad6bd5fa8ce9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'æˆ‘çš„åå­—å«Tom', 'history': '', 'text': 'ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼ŒTomï¼å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘åœ¨è¿™é‡Œä¸ºä½ æä¾›å¸®åŠ©ã€‚ğŸ˜Š'}\n",
      "{'question': 'ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—', 'history': 'Human: æˆ‘çš„åå­—å«Tom\\nAI: ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼ŒTomï¼å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘åœ¨è¿™é‡Œä¸ºä½ æä¾›å¸®åŠ©ã€‚ğŸ˜Š', 'text': 'å½“ç„¶è®°å¾—ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œéšæ—¶ä¸ºä½ æä¾›å¸®åŠ©ã€‚ğŸ˜Š'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹2ï¼šå¯ä»¥é€šè¿‡memory_keyä¿®æ”¹memoryæ•°æ®çš„å˜é‡å",
   "id": "9cc3dea5f06d1385"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:50:38.191410Z",
     "start_time": "2025-10-23T13:50:28.512093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# åˆå§‹åŒ–å¤§æ¨¡å‹\n",
    "llm = ChatOllama(model='deepseek-r1:7b', base_url=\"http://localhost:11434\")\n",
    "# åˆ›å»ºæç¤º\n",
    "# æœ‰ä¸¤ä¸ªè¾“å…¥é”®ï¼šå®é™…è¾“å…¥ä¸æ¥è‡ªè®°å¿†ç±»çš„è¾“å…¥ éœ€ç¡®ä¿PromptTemplateå’ŒConversationBufferMemoryä¸­çš„é”®åŒ¹é…\n",
    "template = \"\"\"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\n",
    "å½“å‰å¯¹è¯å†å²: {chat_his}\n",
    "äººç±»é—®é¢˜: {question}\n",
    "å›å¤:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# åˆ›å»ºConversationBufferMemory(ä¿®æ”¹é»˜è®¤çš„memory key)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_his\")\n",
    "# åˆå§‹åŒ–é“¾\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "# æé—®\n",
    "res1 = chain.invoke({\"question\": \"æˆ‘çš„åå­—å«Tom\"})\n",
    "print(res1)\n",
    "res1 = chain.invoke({\"question\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\"})\n",
    "print(res1)"
   ],
   "id": "83feb97596d0d7b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'æˆ‘çš„åå­—å«Tom', 'chat_his': '', 'text': 'ä½ å¥½ï¼ŒTomï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ'}\n",
      "{'question': 'æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ', 'chat_his': 'Human: æˆ‘çš„åå­—å«Tom\\nAI: ä½ å¥½ï¼ŒTomï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ', 'text': 'å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ŒTomï¼ä½ çš„åå­—æ˜¯Tomã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹3ï¼šä½¿ç”¨ChatPromptTemplate å’Œ return_messages",
   "id": "99b7706ea491b93f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:56:20.147674Z",
     "start_time": "2025-10-23T13:56:08.747972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder,ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "# 2.åˆ›å»ºLLM\n",
    "llm = ChatOllama(model='deepseek-r1:7b', base_url=\"http://localhost:11434\")\n",
    "# 3.åˆ›å»ºPrompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\",\"ä½ æ˜¯ä¸€ä¸ªä¸äººç±»å¯¹è¯çš„æœºå™¨äººã€‚\"),\n",
    "MessagesPlaceholder(variable_name='history'),\n",
    "(\"human\",\"é—®é¢˜ï¼š{question}\")\n",
    "])\n",
    "# 4.åˆ›å»ºMemory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "# 5.åˆ›å»ºLLMChain\n",
    "llm_chain = LLMChain(prompt=prompt,llm=llm, memory=memory)\n",
    "# 6.è°ƒç”¨LLMChain\n",
    "res1 = llm_chain.invoke({\"question\": \"ä¸­å›½é¦–éƒ½åœ¨å“ªé‡Œï¼Ÿ\"})\n",
    "print(res1,end=\"\\n\\n\")\n",
    "res2 = llm_chain.invoke({\"question\": \"æˆ‘åˆšåˆšé—®äº†ä»€ä¹ˆ\"})\n",
    "print(res2)"
   ],
   "id": "6be97e92e26df401",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'ä¸­å›½é¦–éƒ½åœ¨å“ªé‡Œï¼Ÿ', 'history': [HumanMessage(content='ä¸­å›½é¦–éƒ½åœ¨å“ªé‡Œï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='ä¸­å›½é¦–éƒ½åŒ—äº¬ä½äºä¸­å›½ä¸œéƒ¨ï¼Œå…·ä½“ä½äº deletes the Tibet region, Gansu province, and Shanghaiå¸‚ã€‚åŒ—äº¬ä¸ä»…æ˜¯ä¸­å›½çš„æ”¿æ²»ã€ç»æµå’Œæ–‡åŒ–ä¸­å¿ƒï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„å›½é™…å¤§éƒ½å¸‚ä¹‹ä¸€ã€‚', additional_kwargs={}, response_metadata={})], 'text': 'ä¸­å›½é¦–éƒ½åŒ—äº¬ä½äºä¸­å›½ä¸œéƒ¨ï¼Œå…·ä½“ä½äº deletes the Tibet region, Gansu province, and Shanghaiå¸‚ã€‚åŒ—äº¬ä¸ä»…æ˜¯ä¸­å›½çš„æ”¿æ²»ã€ç»æµå’Œæ–‡åŒ–ä¸­å¿ƒï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„å›½é™…å¤§éƒ½å¸‚ä¹‹ä¸€ã€‚'}\n",
      "\n",
      "{'question': 'æˆ‘åˆšåˆšé—®äº†ä»€ä¹ˆ', 'history': [HumanMessage(content='ä¸­å›½é¦–éƒ½åœ¨å“ªé‡Œï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='ä¸­å›½é¦–éƒ½åŒ—äº¬ä½äºä¸­å›½ä¸œéƒ¨ï¼Œå…·ä½“ä½äº deletes the Tibet region, Gansu province, and Shanghaiå¸‚ã€‚åŒ—äº¬ä¸ä»…æ˜¯ä¸­å›½çš„æ”¿æ²»ã€ç»æµå’Œæ–‡åŒ–ä¸­å¿ƒï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„å›½é™…å¤§éƒ½å¸‚ä¹‹ä¸€ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='æˆ‘åˆšåˆšé—®äº†ä»€ä¹ˆ', additional_kwargs={}, response_metadata={}), AIMessage(content='æ‚¨ä¸Šä¸€æ¬¡é—®äº†ï¼šâ€œé—®é¢˜ï¼šæˆ‘åˆšåˆšé—®äº†ä»€ä¹ˆâ€ã€‚', additional_kwargs={}, response_metadata={})], 'text': 'æ‚¨ä¸Šä¸€æ¬¡é—®äº†ï¼šâ€œé—®é¢˜ï¼šæˆ‘åˆšåˆšé—®äº†ä»€ä¹ˆâ€ã€‚'}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "æ€»ç»“ï¼šé€šè¿‡ä¸Šé¢çš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼Œå¯¹äºmemoryï¼ŒPromptTemplate å’Œ ChatPromptTemplateæœ‰ä»¥ä¸‹å‡ ç§åŒºåˆ«ï¼š\n",
    "|ç‰¹æ€§|PromptTemplate|ChatPromptTemplate|\n",
    "|----|----|----|\n",
    "|æ¶ˆæ¯å­˜å‚¨æ—¶æœº|è°ƒç”¨å®Œæˆå|è°ƒç”¨å‰å­˜å‚¨ç”¨æˆ·è¾“å…¥ï¼Œè°ƒç”¨åå­˜å‚¨æ¨¡å‹è¾“å‡º|\n",
    "|æ¶ˆæ¯è°ƒç”¨æ˜¾ç¤º|ç¬¬ä¸€æ¬¡è°ƒç”¨historyå˜é‡ä¸ºç©º|ç¬¬ä¸€æ¬¡historyå˜é‡å°±å·²ç»å­˜å‚¨å®Œæ•´å¯¹è¯ä¿¡æ¯|\n",
    "|æ¶ˆæ¯ç±»å‹|å­—ç¬¦ä¸²|List[BaseMessage]|\n",
    "\n",
    "æ³¨æ„ï¼š\n",
    "æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„ç°è±¡ä¸æ˜¯ bugï¼Œè€Œæ˜¯ LangChain ä¸º ä¿éšœå¯¹è¯ä¸€è‡´æ€§ æ‰€åšçš„åˆ»æ„è®¾è®¡ï¼š\n",
    "1. ç”¨æˆ·æé—®åï¼Œç³»ç»Ÿåº”ç«‹å³\"è®°ä½\"è¯¥é—®é¢˜\n",
    "2. AIå›ç­”åï¼Œè¯¥å“åº”åº”å³åˆ»åŠ å…¥å¯¹è¯ä¸Šä¸‹æ–‡\n",
    "3. è¿”å›ç»™å®¢æˆ·ç«¯çš„ç»“æœåº”åæ˜ æœ€æ–°çŠ¶æ€"
   ],
   "id": "db3df69466cb4cf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4ã€ConversationChain\n",
    "`ConversationChain`å®è´¨ä¸Šå°±æ˜¯å°è£…äº†`LLMChain`å’Œ`ConversationBufferMemory`çš„Chainï¼Œæä¾›äº†é»˜è®¤çš„PromptTemplateå’ŒMemoryï¼Œä½ ä¹Ÿå¯ä»¥ä¸ç”¨ã€‚\n"
   ],
   "id": "5ec1d408a99de4d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹1ï¼šä½¿ç”¨è‡ªå®šä¹‰çš„PromptTemplateï¼Œçœç•¥Memory",
   "id": "f27f6bae804858b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:24:21.799262Z",
     "start_time": "2025-10-23T14:24:08.992469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.chains.conversation.base import ConversationChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# åˆå§‹åŒ–å¤§æ¨¡å‹\n",
    "llm = ChatOllama(model='deepseek-r1:7b', base_url=\"http://localhost:11434\")\n",
    "# åˆ›å»ºæç¤º\n",
    "template = \"\"\"ä½ å¯ä»¥ä¸äººç±»å¯¹è¯ã€‚\n",
    "å½“å‰å¯¹è¯å†å²: {history}\n",
    "äººç±»é—®é¢˜: {input}\n",
    "å›å¤:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# åˆå§‹åŒ–é“¾\n",
    "chain = ConversationChain(llm=llm, prompt=prompt)\n",
    "# æé—®\n",
    "res1 = chain.invoke({\"input\": \"æˆ‘çš„åå­—å«Tom\"})\n",
    "print(res1)\n",
    "res1 = chain.invoke({\"input\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ\"})\n",
    "print(res1)"
   ],
   "id": "4d9f9c5bceb21e95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'æˆ‘çš„åå­—å«Tom', 'history': '', 'response': 'ä½ å¥½ï¼æˆ‘æ˜¯Rï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}\n",
      "{'input': 'æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ', 'history': 'Human: æˆ‘çš„åå­—å«Tom\\nAI: ä½ å¥½ï¼æˆ‘æ˜¯Rï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ', 'response': 'ä½ å¥½ï¼æˆ‘å«Tomã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹2ï¼šä½¿ç”¨å†…ç½®çš„æç¤ºè¯æ¨¡æ¿å’ŒMemory",
   "id": "836d045cb4a2c3ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:30:53.993955Z",
     "start_time": "2025-10-23T14:30:35.650688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.chains.conversation.base import ConversationChain\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# åˆå§‹åŒ–å¤§æ¨¡å‹\n",
    "llm = ChatOllama(model='deepseek-r1:7b', base_url=\"http://localhost:11434\")\n",
    "# åˆå§‹åŒ–é“¾\n",
    "chain = ConversationChain(llm=llm)\n",
    "# æé—®\n",
    "res1 = chain.invoke({\"input\": \"æˆ‘çš„åå­—å«Tom\"})\n",
    "print(res1)\n",
    "res1 = chain.invoke({\"input\": \"è¯·é—®æˆ‘å«ä»€ä¹ˆ\"})\n",
    "print(res1)"
   ],
   "id": "eaea2a20cb6389a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'æˆ‘çš„åå­—å«Tom', 'history': '', 'response': 'Based on the conversation between Tom and the AI, here is an organized summary of the thought process:\\n\\n1. **Understanding the Context**: The user provided their name as \"Tom\" in English, prompting the AI for additional details about his full name.\\n\\n2. **Common Names Consideration**: Since Tom is a common first name, the AI considered possible surnames and middle names associated with it.\\n\\n3. **Possibilities Explored**:\\n   - Tom could be a full name.\\n   - Tom might have a middle name or an Asian surname.\\n   - There\\'s also the possibility of changing his name to another.\\n\\n4. **Conclusion**: Without further information, the best approach is to request more details from Tom to provide a precise response.\\n\\nThis structured thought process leads to the conclusion that additional information is needed before providing a specific answer.'}\n",
      "{'input': 'è¯·é—®æˆ‘å«ä»€ä¹ˆ', 'history': 'Human: æˆ‘çš„åå­—å«Tom\\nAI: Based on the conversation between Tom and the AI, here is an organized summary of the thought process:\\n\\n1. **Understanding the Context**: The user provided their name as \"Tom\" in English, prompting the AI for additional details about his full name.\\n\\n2. **Common Names Consideration**: Since Tom is a common first name, the AI considered possible surnames and middle names associated with it.\\n\\n3. **Possibilities Explored**:\\n   - Tom could be a full name.\\n   - Tom might have a middle name or an Asian surname.\\n   - There\\'s also the possibility of changing his name to another.\\n\\n4. **Conclusion**: Without further information, the best approach is to request more details from Tom to provide a precise response.\\n\\nThis structured thought process leads to the conclusion that additional information is needed before providing a specific answer.', 'response': 'è¯·æä¾›æ›´å¤šçš„ä¿¡æ¯ä»¥å¸®åŠ©æˆ‘æ›´å¥½åœ°ç†è§£æ‚¨çš„åå­—ã€‚'}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5ã€ConversationBufferWindowMemory\n",
   "id": "c098218941593644"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
